{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en Ciencia de Datos UTN FRC\n",
    "## Modulo 5\n",
    "\n",
    "### Trabajo práctico \n",
    "\n",
    "#### Alumno: Pavelek Israel\n",
    "\n",
    "# Sentiment Analysis sobre reviews\n",
    "\t\t\t\t\t\t\n",
    "A través de este trabajo se busca poder integrar nociones y conocimientos sobre NLP vistas en el módulo, así como en los previos para generar un modelo de machine learning.\n",
    "El objetivo que van a tener es construir un clasificador el cual pueda predecir si una revisión realizada por un usuario es positiva o negativa (buena o mala).\n",
    "Para ello, utilizaremos un conjunto de datos que pertenece a la plataforma ​Yelp​. Esta, posee una red de usuarios, los cuales realizan opiniones sobre lugares nocturnos, espacios culturales, locales comerciales, entre otros.\n",
    "El dataset a trabajar se encuentra en el siguiente ​link​. Deberán realizar un análisis de features, así como su preparación necesaria antes de iniciar el desarrollo del modelo.\n",
    "\t\t\t\t\t\t\n",
    "Objetivos\n",
    "Deberán generar un modelo de machine learning el cual pueda clasificar review en inglés para la plataforma Yelp. Es decir, nuestro modelo recibirá una review de un usuario, y deberá ser capaz de determinar si esta es positiva o negativa.\n",
    "\n",
    "Dataset\n",
    "\n",
    "Las features que contiene este dataset son las siguientes:\n",
    "\t\t\t\t\n",
    "* business_id: identificador del negocio al que se está realizando la review.\n",
    "* cool: cantidad de votos por haber sido una review “cool”.\n",
    "* date: fecha de realización de la revisión\n",
    "* funny: cantidad de votos para una revisión “divertida”.\n",
    "* review_id: identificador único de revisión (ofuscado).\n",
    "* stars: cantidad de estrellas otorgadas por el usuario en referencia a la review.\n",
    "* text: revisión realizada por el usuario sobre un determinado negocio.\n",
    "* useful: cantidad de votos recibido por los usuarios a los cuales le resultó útil la revisión.\n",
    "* user_id: id del usuario en la plataforma (ofuscado)\n",
    "\n",
    "Consideraciones\n",
    "\n",
    "* No contamos con una variable target como pasa en problemas de la vida real. Por ello, un desafío extra que se presenta es cómo definir un target, basado en las features del dataset.\n",
    " \t\t\t\t\n",
    "* Muchas veces cuando importamos un dataset pandas infiere que valor podría ser, de no encontrar un valor conocido pone uno por defecto.Validar que los tipos de datos de las features después de importarse correspondan con su valor intrínseco es una buena práctica.\n",
    "\n",
    "* Haga una rápida exploración de valores atípicos (outliers) del conjunto de datos. Realice los gráficos que considere pertinente para entender la naturaleza del problema.\n",
    "\n",
    "\n",
    "Evaluación\n",
    " \t\t\t\t\t\t\t\t\n",
    "Para la evaluación de los modelos vamos a utilizar las siguientes métricas:\n",
    " \t\t\t\t\t\t\t\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "* Análisis de AUC ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import  TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from langdetect import DetectorFactory, detect, detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews_yelp_nn.csv.gz', compression='gzip', sep=\"\\t\", error_bad_lines=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos varias columnas que no aportan información como los IDs y la fecha. Luego algunas columnas son categoricas y deberian ser numéricas como 'Cool'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removemos las columnas que no aportan al modelo\n",
    "df_work= df.drop(columns=['date', 'review_id', 'user_id','business_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Las ordeno dejando al final el texto (solo por un tema visual)\n",
    "df_work=df_work[['cool','funny','useful','stars','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos si tenemos Nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Como son muy pocos los valores Nulos eliminamos estas entradas\n",
    "df_work=df_work.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modificamos la columna cool y la hacemos numérica\n",
    "df_work[\"cool\"]=df_work[\"cool\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las columnas Cool, Funny y Usefull, poseen una media baja, por lo que vemos que todos los valores son bajos. Seguramente contengamos outliers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chequeamos que no sigamos conteniendo nulos\n",
    "df_work.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20,6))\n",
    "\n",
    "sns.boxplot(x=df_work['cool'], ax=axes[0][0])\n",
    "sns.boxplot(x=df_work['funny'], ax=axes[0][1])\n",
    "sns.boxplot(x=df_work['useful'], ax=axes[0][2])\n",
    "sns.boxplot(x=df_work['stars'], ax=axes[0][3])\n",
    "\n",
    "sns.violinplot(x=df_work['cool'], ax=axes[1][0], palette=\"Reds\")\n",
    "sns.violinplot(x=df_work['funny'], ax=axes[1][1], palette=\"Greens\")\n",
    "sns.violinplot(x=df_work['useful'], ax=axes[1][2], palette=\"Blues\")\n",
    "sns.violinplot(x=df_work['stars'], ax=axes[1][3], palette=\"Oranges\")\n",
    "\n",
    "\n",
    "sns.histplot(data=df_work, x=df_work['cool'],  ax=axes[2][0])\n",
    "sns.histplot(data=df_work, x=df_work['funny'],ax=axes[2][1])\n",
    "sns.histplot(data=df_work, x=df_work['useful'],  ax=axes[2][2])\n",
    "sns.histplot(data=df_work, x=df_work['stars'],  ax=axes[2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile1, quantile3= np.percentile(df_work['useful'],[10,90])\n",
    "print(quantile1,quantile3)\n",
    "df_work=df_work[(df_work.useful <= quantile3) & (df_work.useful >= quantile1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile1, quantile3= np.percentile(df_work['stars'],[10,90])\n",
    "print(quantile1,quantile3)\n",
    "df_work=df_work[(df_work.stars <= quantile3) & (df_work.stars >= quantile1 )]\n",
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile1, quantile3= np.percentile(df_work['funny'],[10,90])\n",
    "print(quantile1,quantile3)\n",
    "df_work=df_work[(df_work.funny <= quantile3) & (df_work.funny >= quantile1 )]\n",
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile1, quantile3= np.percentile(df_work['cool'],[10,90])\n",
    "print(quantile1,quantile3)\n",
    "df_work=df_work[(df_work.cool <= quantile3) & (df_work.cool >= quantile1 )]\n",
    "df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las columnas cool funny y useful son variables booleanas mientras que stars posee un valor entre 1 y 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que las columnas cool, funny, stars y usefull solo poseen valores enteros, sin comas, pasamos todo a entero\n",
    "df_work[[\"cool\",\"funny\",\"stars\",\"useful\"]]=df_work[[\"cool\",\"funny\",\"stars\",\"useful\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Vamos a ver la longitudes de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work[\"length\"] = df_work.text.apply(len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a setear como nuestro Target stars, por lo tanto nos quedamos con los valores extremos 1 y 5 como una reseña negativa y positiva respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bad_good = df_work.stars.isin([1, 5])\n",
    "data_bad_good = df_work[filter_bad_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removemos de nuestro Corpus todos los puntos y StopWords\n",
    "\n",
    "stemmer = nltk.RSLPStemmer()\n",
    "stopwords = list(stopwords.words(\"english\"))\n",
    "punctuation = [word for word in string.punctuation]\n",
    "punctuation += ['...', '  ', '\\n','!','!!','!!!','!!!!']+ list(\"0123456789\")\n",
    "\n",
    "def remove_punctuation(serie, stopwords):\n",
    "    aux = list()\n",
    "    for el in serie:\n",
    "        for word in stopwords:\n",
    "            el = el.replace(word,' ')\n",
    "        aux.append(el)\n",
    "    return aux\n",
    "\n",
    "def remove_stopwords(serie, stopwords):\n",
    "    tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "    result_serie= list()\n",
    "    for row in serie:\n",
    "        aux = list()\n",
    "        text_row = tokenizer.tokenize(row.lower())\n",
    "        for word in text_row:\n",
    "            if word not in stopwords: # stopwords\n",
    "                aux.append(word)\n",
    "        result_serie.append(' '.join(aux))\n",
    "    return result_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_good.text = data_bad_good.text.str.lower()\n",
    "data_bad_good.text = remove_stopwords(data_bad_good.text, punctuation)\n",
    "data_bad_good.text = remove_stopwords(data_bad_good.text, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Veamos la distribución de las reseñas en función de las estrellas y la longitud.\n",
    "\n",
    "g = sns.FacetGrid(data_bad_good,col='stars')\n",
    "g.map(plt.hist,'length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='stars',y='length',data=data_bad_good,palette='rainbow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='stars',data=data_bad_good,palette='rainbow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = data_bad_good.groupby('stars').mean()\n",
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x ='length', hue='stars',data= data_bad_good)\n",
    "plt.box(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vamos a detectar el idioma en el que fueron realizadas las reseñas\n",
    "\n",
    "def get_review_language(row):\n",
    "    try:\n",
    "        language = detect(row)\n",
    "    except:\n",
    "        language = \"error\"\n",
    "        \n",
    "    return language\n",
    "\n",
    "data_bad_good[\"language\"] = data_bad_good['text'].apply(get_review_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_good[\"language\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Como vemos que mayoritariamente estan escritas en ingles, solos nos quedamos con estas reseñas y descartamos las demas.\n",
    "data_bad_good2=data_bad_good[data_bad_good[\"language\"]=='en']\n",
    "data_bad_good2\n",
    "data_bad_good2.to_csv('reviews_yelp_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No nos quedamos con reseñas muy largas que probablemente sean de personas que cuenten cosas que no sean significativas, ni muy cortas\n",
    "\n",
    "quantile1, quantile3= np.percentile(data_bad_good2[data_bad_good2['stars']==1].length,[10,90])\n",
    "print(quantile1,quantile3)\n",
    "aux1=data_bad_good2[(data_bad_good2['stars']==1) & (data_bad_good2['length']>quantile1) & (data_bad_good2['length']<quantile3) ]\n",
    "\n",
    "quantile1, quantile3= np.percentile(data_bad_good2[data_bad_good2['stars']==5].length,[10,90])\n",
    "print(quantile1,quantile3)\n",
    "aux2=data_bad_good2[(data_bad_good2['stars']==5) & (data_bad_good2['length']>quantile1) & (data_bad_good2['length']<quantile3) ]\n",
    "\n",
    "data_bad_good = pd.concat([aux1,aux2])\n",
    "#df_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_good2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A modo de entrenar con la misma cantidad de reseñas igualamos las cantidades al menor. \n",
    "aux1=data_bad_good2[data_bad_good2['stars']==5].sample(data_bad_good2[data_bad_good2['stars']==1].shape[0])\n",
    "aux2=data_bad_good2[data_bad_good2['stars']==1]\n",
    "data_bad_good3 = pd.concat([aux1,aux2])\n",
    "data_bad_good3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='stars',data=data_bad_good3,palette='rainbow')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = CountVectorizer()\n",
    "\n",
    "X = vectorize.fit_transform(data_bad_good3.text)\n",
    "Y = data_bad_good3.stars.map({5: 1, 1: 0}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#model = MultinomialNB()\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas del desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytrue, langdetect_preds_binary))\n",
    "print(classification_report(ytrue, spacy_preds_binary))\n",
    "print(classification_report(ytrue, langid_preds_binary))\n",
    "print(classification_report(ytrue, fasttext_preds_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
