{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### Importar TensorFlow 2.0  y otras librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1955,
     "status": "ok",
     "timestamp": 1598575780618,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "zWrJnG1jZd00",
    "outputId": "2e9d7cd6-425c-4570-ce56-ae79a98cea5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "### Descarga del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1598575820273,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "pD_55cOxLkAb",
    "outputId": "ed61a2f8-be9b-474b-acd8-95f7cf2b278b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/jorditorresBCN/Deep-Learning-Introduccion-practica-con-Keras/master/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt\n",
      "204800/203286 [==============================] - 0s 1us/step\n",
      "212992/203286 [===============================] - 0s 1us/step\n",
      "Longitud del texto:        203251 carácteres\n",
      "El texto está compuesto de estos 92 carácteres:\n",
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡', '…']\n"
     ]
    }
   ],
   "source": [
    "path_to_fileDL = tf.keras.utils.get_file('DL-Introduccion-practica-con-Keras-1aParte.txt', 'https://raw.githubusercontent.com/jorditorresBCN/Deep-Learning-Introduccion-practica-con-Keras/master/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt')  \n",
    "\n",
    "#path_to_fileDL = tf.keras.utils.get_file('Shakespear.txt', 'https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt')\n",
    "\n",
    "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
    "print('Longitud del texto:        {} carácteres'.format(len(text)))\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
    "print (vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1598575832260,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "IalZLbvOzf-F",
    "outputId": "8cf17e8a-fed1-4484-a0a1-afc887f2ad10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  '\\n':   0,\n",
      "  '\\r':   1,\n",
      "  ' ' :   2,\n",
      "  '!' :   3,\n",
      "  '\"' :   4,\n",
      "  '#' :   5,\n",
      "  '%' :   6,\n",
      "  \"'\" :   7,\n",
      "  '(' :   8,\n",
      "  ')' :   9,\n",
      "  '*' :  10,\n",
      "  '+' :  11,\n",
      "  ',' :  12,\n",
      "  '-' :  13,\n",
      "  '.' :  14,\n",
      "  '/' :  15,\n",
      "  '0' :  16,\n",
      "  '1' :  17,\n",
      "  '2' :  18,\n",
      "  '3' :  19,\n",
      "  '4' :  20,\n",
      "  '5' :  21,\n",
      "  '6' :  22,\n",
      "  '7' :  23,\n",
      "  '8' :  24,\n",
      "  '9' :  25,\n",
      "  ':' :  26,\n",
      "  ';' :  27,\n",
      "  '<' :  28,\n",
      "  '=' :  29,\n",
      "  '>' :  30,\n",
      "  '?' :  31,\n",
      "  '@' :  32,\n",
      "  'A' :  33,\n",
      "  'B' :  34,\n",
      "  'C' :  35,\n",
      "  'D' :  36,\n",
      "  'E' :  37,\n",
      "  'F' :  38,\n",
      "  'G' :  39,\n",
      "  'H' :  40,\n",
      "  'I' :  41,\n",
      "  'J' :  42,\n",
      "  'K' :  43,\n",
      "  'L' :  44,\n",
      "  'M' :  45,\n",
      "  'N' :  46,\n",
      "  'O' :  47,\n",
      "  'P' :  48,\n",
      "  'Q' :  49,\n",
      "  'R' :  50,\n",
      "  'S' :  51,\n",
      "  'T' :  52,\n",
      "  'U' :  53,\n",
      "  'V' :  54,\n",
      "  'W' :  55,\n",
      "  'X' :  56,\n",
      "  'Y' :  57,\n",
      "  '[' :  58,\n",
      "  ']' :  59,\n",
      "  '_' :  60,\n",
      "  'a' :  61,\n",
      "  'b' :  62,\n",
      "  'c' :  63,\n",
      "  'd' :  64,\n",
      "  'e' :  65,\n",
      "  'f' :  66,\n",
      "  'g' :  67,\n",
      "  'h' :  68,\n",
      "  'i' :  69,\n",
      "  'j' :  70,\n",
      "  'k' :  71,\n",
      "  'l' :  72,\n",
      "  'm' :  73,\n",
      "  'n' :  74,\n",
      "  'o' :  75,\n",
      "  'p' :  76,\n",
      "  'q' :  77,\n",
      "  'r' :  78,\n",
      "  's' :  79,\n",
      "  't' :  80,\n",
      "  'u' :  81,\n",
      "  'v' :  82,\n",
      "  'w' :  83,\n",
      "  'x' :  84,\n",
      "  'y' :  85,\n",
      "  'z' :  86,\n",
      "  '\\xad':  87,\n",
      "  'ÿ' :  88,\n",
      "  'Š' :  89,\n",
      "  '‡' :  90,\n",
      "  '…' :  91,\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "for char,_ in zip(char2idx, range(len(vocab))):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1598575870343,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "ML-DuUyi_aHy"
   },
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1598575870720,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "l1VKcQHcymwb",
    "outputId": "9b81364e-f937-45b5-e76c-73cd0c8708f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto: 'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fun'\n",
      "array([48, 78, 75, 72, 75, 67, 75,  1,  0, 37, 74,  2, 17, 25, 21, 19, 12,\n",
      "        2, 41, 79, 61, 61, 63,  2, 33, 79, 69, 73, 75, 82,  2, 76, 81, 62,\n",
      "       72, 69, 63, 75,  2, 51, 65, 67, 81, 74, 64, 61,  2, 38, 81, 74])\n"
     ]
    }
   ],
   "source": [
    "print ('texto: {}'.format(repr(text[:50])))\n",
    "print ('{}'.format(repr(text_as_int[:50])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Preparar los datos para entrenar la RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6169,
     "status": "ok",
     "timestamp": 1598575896769,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "0UHJDA39zf-O"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "seq_length = 100\n",
    " \n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5360,
     "status": "ok",
     "timestamp": 1598575896776,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "l4hkDU3i7ozi",
    "outputId": "7734763f-ba35-423b-a31a-aa2fc0f7c552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n",
      "'(o el decimotercero segun otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por'\n",
      "' primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su pri'\n",
      "'mera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccio'\n",
      "'n que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redaccion, Arkady esta utilizando '\n",
      "'un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo,'\n",
      "' que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de'\n",
      "' nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de '\n",
      "'aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Proces'\n",
      "'sor Units), que solo cuestan alrededor de 100 euros, que estarian en la lista del Top500 hace unos po'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(10):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1598575919340,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1598575973015,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "GNbw-iR0ymwj",
    "outputId": "21e9587d-e4ef-4a17-e496-5bb3d9c5aeb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion'\n",
      "Target data: 'rologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1598575974580,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "0eBu9WZG84i0",
    "outputId": "2097b51c-ea62-444c-af6e-38279a795b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1598575977893,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "p2pGotuNzf-S",
    "outputId": "c92a5fe8-b2fd-422f-82ae-8fd3953b24c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "### Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1598575983757,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2277,
     "status": "ok",
     "timestamp": 1598576183751,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1545,
     "status": "ok",
     "timestamp": 1598576183761,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1598576189083,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "PpHGXDMcZ0Zt",
    "outputId": "944dc786-bb44-4d7f-ce23-e99544b2f2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           23552     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 92)            94300     \n",
      "=================================================================\n",
      "Total params: 5,364,828\n",
      "Trainable params: 5,364,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1420,
     "status": "ok",
     "timestamp": 1598576192887,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "C-_70kKAPrPU",
    "outputId": "e9ab39d1-de0e-4243-b699-351f43ca946e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (64, 100) # (batch_size, sequence_length)\n",
      "Target: (64, 100) # (batch_size, sequence_length)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
    "  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8103,
     "status": "ok",
     "timestamp": 1598576204680,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "udE_6eTldMhB",
    "outputId": "d5ac2fd7-8583-4e3f-c289-9c596cb13d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  (64, 100, 92) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):  \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2162,
     "status": "ok",
     "timestamp": 1598576208947,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1396,
     "status": "ok",
     "timestamp": 1598576211283,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "YqFMUQc_UFgM",
    "outputId": "bae87569-3119-466b-ca87-b465cd882fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 78, 91, 10, 58, 73, 46,  2, 87, 17, 74, 43, 36, 80, 35, 23, 52,\n",
       "       21,  5, 20, 71, 62, 24, 65, 29, 28,  9, 55,  0, 49, 47, 33, 65, 14,\n",
       "       40, 35, 55, 10, 29,  2,  4, 17,  5, 79, 87, 74, 81, 43, 64, 68,  1,\n",
       "       52,  2, 40, 64, 14, 20, 10, 82, 23, 59, 48, 86, 21, 45, 76, 64, 30,\n",
       "       54, 85, 91, 88, 12, 66, 77, 70, 91, 26, 17, 28, 58, 21, 72, 50, 32,\n",
       "       38, 44,  8, 52, 70, 61,  4, 79, 50, 43, 38, 19, 79, 58, 88])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1598576214304,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2026,
     "status": "ok",
     "timestamp": 1598576215290,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieSJdchZggUj"
   },
   "source": [
    "Configurar el *checkpoints*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1598576229052,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    " # directorio\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# nombre fichero\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "*Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 124582,
     "status": "ok",
     "timestamp": 1598576355587,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "UK-hmKjYVoll",
    "outputId": "ed8261d3-b25d-40a3-d2b0-c7c2514bda4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 8/31 [======>.......................] - ETA: 48s - loss: 3.6871"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-85058e8c8b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "### Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1598577214527,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "zk2WJ2-XjkGz",
    "outputId": "31ce278d-7129-41cb-b514-e33d23c58e7c"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1598577216416,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1598577218183,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "\n",
    "  num_generate = 500\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "\n",
    "\n",
    "  temperature = 0.5\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 131339,
     "status": "ok",
     "timestamp": 1598569702350,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "ktovv0RFhrkn",
    "outputId": "f3590a00-1b59-4d5c-c246-ec2e57d77e25"
   },
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"Alcohol \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2961,
     "status": "ok",
     "timestamp": 1598577238447,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "PsNst9-GeiZo",
    "outputId": "b179d09c-004e-4124-f887-4752e66cc268"
   },
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"entrenar un modelo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3365,
     "status": "ok",
     "timestamp": 1598570090169,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "NFOd58ksem1a",
    "outputId": "c77c8bab-fb85-442a-d420-bf88ae81260a"
   },
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"un modelo es\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135462,
     "status": "ok",
     "timestamp": 1598569706727,
     "user": {
      "displayName": "Charly Vazquez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu2lE4PrP9Yam_bgiYa3M9ErEb2w64C1ZM-tMHMw=s64",
      "userId": "18086734693371059234"
     },
     "user_tz": 180
    },
    "id": "-5JDvs0m9TZg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:tpu_hw_notebook",
    "kind": "private"
   },
   "name": "7.RedesNeuronalesRecurrentes.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/text/text_generation.ipynb",
     "timestamp": 1565900142296
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
